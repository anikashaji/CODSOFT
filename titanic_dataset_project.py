# -*- coding: utf-8 -*-
"""Titanic Dataset Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JabJnReRoAeIDvTj_7JIw_UZylGiKv-k
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler,MinMaxScaler
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('/content/Titanic-Dataset.csv')

# Display the first few rows
print(df.head())

#Finds null values
df.isnull()

sns.heatmap(df.isnull(),yticklabels=False, cbar=False,cmap='flare_r')

sns.set_style('whitegrid')
sns.countplot(x='Survived',data=df)

sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Sex',data=df,palette = 'RdBu_r')

sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Pclass',data=df,palette = 'rainbow')

#Count of people within these ranges of age
sns.distplot(df['Age'].dropna(),kde=False,color='darkred',bins=40)

df['Age'].hist(bins=30,color='darkblue',alpha=0.3)

sns.countplot(x='SibSp',data=df)

#Avg fare of the people who have bought tickets
df['Fare'].hist(color='green',bins=40,figsize=(8,4))

"""# **DATA CLEANING**"""

plt.figure(figsize=(12,7))
sns.boxplot(x='Pclass',y='Age',data=df,palette='winter')

def input_age(cols):
  Age = cols[0]
  Pclass = cols[1]
  if pd.isnull(Age):
    if Pclass == 1:
      return 37
    elif Pclass == 2:
      return 29
    else:
      return 24
  else:
    return Age

df['Age'] = df[['Age','Pclass']].apply(input_age,axis=1)

sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='flare_r')

#Drop Cabin column
df.drop('Cabin',axis=1,inplace=True)

df.head()

"""# **# Converting Categorical Features**"""

df.info()

pd.get_dummies(df['Embarked'],drop_first=True).head()

sex = pd.get_dummies(df['Sex'],drop_first=True)
embark = pd.get_dummies(df['Embarked'],drop_first=True)

df.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)

df.head()

df = pd.concat([df,sex,embark],axis=1)

df.head()

# Sample data
data = {'Q': [False, False, False, False, False],
        'S': [True, False, True, True, True]}

# Creating the DataFrame
df = pd.DataFrame(data)

# Converting boolean values to integers
df = df.astype(int)

print(df)

"""# **LOGISTIC REGRESSION MODEL**"""

df.drop('Survived',axis=1).head()

df['Survived'].head()

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(df.drop('Survived',axis=1),
                                                    df['Survived'], test_size=0.30,
                                                    random_state=101)

"""# **TRAINING AND PREDICTING**"""

from sklearn.linear_model import LogisticRegression

logmodel = LogisticRegression()
logmodel.fit(x_train,y_train)

LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, max_iter=100,
                   multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,
                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)

predictions = logmodel.predict(x_test)

from sklearn.metrics import confusion_matrix

accuracy = confusion_matrix(y_test,predictions)

accuracy

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test,predictions)
accuracy

predictions

